{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b86b064-5943-4a78-b205-f2665d5e05f4",
   "metadata": {},
   "source": [
    "## Generate MCMC Sample data for the objective and goal\n",
    "\n",
    "Given the historic data with clicks, impressions, spend, reach, and so on, build a model that can predict the probability of a specific _spend_ will result in clicks, impressions, reach, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b75889c-44e5-4857-99ae-9c6f7ded2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING CONTROL to display or ignore all warnings\n",
    "'''\n",
    "import warnings; warnings.simplefilter('ignore')     #switch betweeb 'default' and 'ignore'\n",
    "import traceback\n",
    "\n",
    "''' Set debug flag to view extended error messages; else set it to False to turn off debugging mode '''\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d075ec77-0838-4c9c-84fe-5536d5481b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional __PROPATTR__-libraries in OPTIMIZATION-package of BUDGET-module imported successfully!\n",
      "All functional RWADSDATA-libraries in OPTIMIZATION-package of BUDGET-module imported successfully!\n",
      "All functional RWADSDATA-libraries in OPTIMIZATION-package of BUDGET-module imported successfully!\n",
      "All functional APP-libraries in REZAWARE-package of REZAWARE-module imported successfully!\n",
      "__propAttr__ Class initialization complete\n",
      "All functional __PROPATTR__-libraries in LOADER-package of ETL-module imported successfully!\n",
      "All functional SPARKFILE-libraries in LOADER-package of ETL-module imported successfully!\n",
      "__propAttr__ Class initialization complete\n",
      "sparkFile Class initialization complete\n",
      "rwAdsData Class initialization complete\n",
      "\n",
      "read and write dataset for MCMC sampling class initialization and load complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "# import tensorflow_probability as tfp\n",
    "# import tensorflow as tf\n",
    "\n",
    "proj_dir = os.path.abspath(os.pardir)\n",
    "sys.path.insert(1,proj_dir.split('mining/')[0])\n",
    "# from rezaware.modules.etl.loader import sparkRDBM as db\n",
    "# from rezaware.modules.etl.loader import sparkFile as file\n",
    "from mining.modules.budget.optimization import rwAdsDataFile as file\n",
    "\n",
    "''' restart initiate classes '''\n",
    "if debug:\n",
    "    import importlib\n",
    "    # db = importlib.reload(db)\n",
    "    file=importlib.reload(file)\n",
    "    # attr=importlib.reload(attr)\n",
    "\n",
    "__desc__ = \"read and write dataset for MCMC sampling\"\n",
    "\n",
    "clsFile = file.dataWorkLoads(\n",
    "    desc = \"optimizing action_type budgets for an ad\",\n",
    "    f_store_mode='local-fs',\n",
    "    f_store_root=proj_dir.split('mining/')[0],\n",
    "    jar_dir=None,\n",
    ")\n",
    "# if clsSDB.session:\n",
    "#     clsSDB._session.stop\n",
    "print(\"\\n%s class initialization and load complete!\" % __desc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807f684-dc81-4a00-ac94-08f04dc73249",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e79c74-943e-40d4-b4e6-6080c3b2d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/04 21:49:44 WARN Utils: Your hostname, FarmRaider2 resolves to a loopback address: 127.0.1.1; using 192.168.2.85 instead (on interface enp3s0)\n",
      "25/03/04 21:49:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "25/03/04 21:49:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/04 21:49:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/03/04 21:49:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error]rwAdsData function <read_realm> name 'obj_sdf' is not defined\n",
      "Loaded outcome_leads_checkout.csv 58280 rows\n"
     ]
    }
   ],
   "source": [
    "__def_date_attr__=\"updated_time\"\n",
    "__def_realm__='OBJECTIVE'\n",
    "__def_obj__ = 'OUTCOME_LEADS'\n",
    "__def_opt_goal__= 'checkout'  # action group\n",
    "\n",
    "_fpath = \"mining/data/budget/optimization/objective\"\n",
    "_fname = \"_\".join([__def_obj__.lower(),__def_opt_goal__.lower()])\n",
    "_fname +=\".csv\"\n",
    "\n",
    "# kwargs = {\n",
    "#     \"REALMFILTATTR\" : 'objective',\n",
    "#     \"REALMFILTLIST\" : [__def_obj__],\n",
    "#     \"UNIXTIMESTAMP\" : __def_date_attr__,\n",
    "# }\n",
    "sdf = clsFile.read_realm(\n",
    "    realm = __def_realm__,\n",
    "    to_date = None,\n",
    "    from_date=None,\n",
    "    fname = _fname,\n",
    "    fpath = _fpath,\n",
    "    # **kwargs,\n",
    ")\n",
    "print(\"Loaded %s %d rows\" % (_fname, sdf.count()))# sdf.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133706dc-40d0-407c-aaa0-446be1342de0",
   "metadata": {},
   "source": [
    "## Hamiltonian Monte Carlo for MCMC sampline\n",
    "* Use Gaussian Process (GP) to model complex time-dependent patterns\n",
    "* How to Incorporate DateTime into the Bayesian Model? To capture the effect of time in ad performance, you can:\n",
    "   * Add a Time-Varying Component (Temporal Effects).\n",
    "   * Treat time (e.g., days_since_start) as a continuous variable.\n",
    "   * Model seasonality or trends using a Gaussian Process (GP) or a hierarchical time-series structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "168fbec2-2b24-4151-8890-bfacee32e9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "(58280,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "clicks = np.array([x['clicks'] for x in _obj_goal_sdf.select('clicks').collect()]).astype(np.float32)\n",
    "clicks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82486bc-557e-4bd6-9ef2-7df43e718aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd0f71-f22d-4e2a-a844-57ee78f589e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# Simulated Ad Performance Data\n",
    "# spend = np.array([x['spend'] for x in _obj_goal_sdf.select('spend').collect()]).astype(np.float32)\n",
    "spend = np.array([100, 200, 300, 400, 500], dtype=np.float32)  # Ad spend per campaign\n",
    "# clicks = np.array([x['clicks'] for x in _obj_goal_sdf.select('clicks').collect()]).astype(np.float32)\n",
    "clicks = np.array([50, 150, 300, 450, 600], dtype=np.float32)  # Observed clicks\n",
    "conversions = np.array([5, 20, 45, 80, 110], dtype=np.float32)  # Observed conversions\n",
    "\n",
    "# Define Bayesian Model\n",
    "def model():\n",
    "    # Priors\n",
    "    alpha = yield tfd.Gamma(concentration=2.0, rate=2.0, name=\"alpha\")  # Click rate shape\n",
    "    ctr = yield tfd.Beta(concentration1=2.0, concentration0=5.0, name=\"ctr\")  # Conversion rate\n",
    "\n",
    "    # Click Model (Poisson)\n",
    "    lambda_clicks = spend * alpha\n",
    "    clicks_pred = yield tfd.Poisson(rate=lambda_clicks, name=\"clicks_pred\")\n",
    "\n",
    "    # Conversion Model (Binomial)\n",
    "    conversions_pred = yield tfd.Binomial(total_count=clicks_pred, probs=ctr, name=\"conversions_pred\")\n",
    "\n",
    "# MCMC Inference using Hamiltonian Monte Carlo (HMC)\n",
    "def run_mcmc():\n",
    "    model_joint = tfd.JointDistributionCoroutine(model)\n",
    "\n",
    "    # Observed data\n",
    "    def target_log_prob_fn(alpha, ctr):\n",
    "        return model_joint.log_prob(alpha, ctr, clicks, conversions)\n",
    "\n",
    "    # HMC sampler\n",
    "    num_results = 2000\n",
    "    num_burnin_steps = 500\n",
    "\n",
    "    kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "        target_log_prob_fn=target_log_prob_fn, step_size=0.1, num_leapfrog_steps=3\n",
    "    )\n",
    "\n",
    "    samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "        num_results=num_results,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        current_state=[tf.constant(1.0), tf.constant(0.1)],  # Initial values for alpha & ctr\n",
    "        kernel=kernel\n",
    "    )\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Run MCMC\n",
    "samples = run_mcmc()\n",
    "\n",
    "# Plot results\n",
    "plt.hist(samples[0], bins=30, alpha=0.6, label=\"Alpha (Click Rate)\")\n",
    "plt.hist(samples[1], bins=30, alpha=0.6, label=\"CTR (Conversion Rate)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d1a973-a5eb-41b3-a586-5b3661abed57",
   "metadata": {},
   "source": [
    "## Write objective & goal data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dfc39f3-8dd5-4477-8e90-41c85abee3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1078:============================================>           (4 + 1) / 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved 58280 data rows to /HOME/NUWAN/WORKSPACE/MADGICX/MINING/DATA/BUDGET/OPTIMIZATION/OBJECTIVE/OUTCOME_LEADS_CHECKOUT.CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "__def_date_attr__=\"updated_time\"\n",
    "__def_realm__='OBJECTIVE'\n",
    "__def_obj__ = 'OUTCOME_LEADS'\n",
    "__def_opt_goal__\n",
    "\n",
    "_fpath = \"mining/data/budget/optimization/objective\"\n",
    "_fname = \"_\".join([__def_obj__.lower(),__def_opt_goal__.lower()])\n",
    "_fname +=\".csv\"\n",
    "\n",
    "write_data = clsFile.write_realm(\n",
    "    realm=__def_realm__,\n",
    "    data =_obj_goal_sdf,\n",
    "    fname=_fname,\n",
    "    fpath=_fpath,\n",
    ")\n",
    "print(\"saved %d data rows to %s\" \n",
    "      %(_obj_goal_sdf.count(), write_data.upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea18764-6586-4a42-8175-e597caef6fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_id: long (nullable = true)\n",
      " |-- ad_id: long (nullable = true)\n",
      " |-- adset_id: long (nullable = true)\n",
      " |-- campaign_id: long (nullable = true)\n",
      " |-- updated_time: date (nullable = true)\n",
      " |-- impressions: integer (nullable = true)\n",
      " |-- frequency: double (nullable = true)\n",
      " |-- reach: integer (nullable = true)\n",
      " |-- CTR: double (nullable = true)\n",
      " |-- CPP: double (nullable = true)\n",
      " |-- CPC: double (nullable = true)\n",
      " |-- CPM: double (nullable = true)\n",
      " |-- spend: double (nullable = true)\n",
      " |-- clicks: integer (nullable = true)\n",
      " |-- objective: string (nullable = true)\n",
      " |-- account_currency: string (nullable = true)\n",
      " |-- business_country_code: string (nullable = true)\n",
      " |-- business_city: string (nullable = true)\n",
      " |-- business_state: string (nullable = true)\n",
      " |-- timezone_name: string (nullable = true)\n",
      " |-- d1_view: double (nullable = true)\n",
      " |-- d7_view: double (nullable = true)\n",
      " |-- d28_view: double (nullable = true)\n",
      " |-- d1_click: double (nullable = true)\n",
      " |-- d7_click: double (nullable = true)\n",
      " |-- d28_click: double (nullable = true)\n",
      " |-- purchase_value: double (nullable = true)\n",
      " |-- purchase_roas: double (nullable = true)\n",
      " |-- checkout_offsite_conversion__fb_pixel_add_to_cart: double (nullable = true)\n",
      " |-- checkout_offsite_conversion__fb_pixel_initiate_checkout: double (nullable = true)\n",
      " |-- checkout_offsite_conversion__fb_pixel_add_payment_info: double (nullable = true)\n",
      " |-- custom_conversions_app_custom_event__other: double (nullable = true)\n",
      " |-- custom_conversions_offsite_conversion__fb_pixel_custom: double (nullable = true)\n",
      " |-- custom_conversions_omni_custom: double (nullable = true)\n",
      " |-- lead_generation_offsite_conversion__fb_pixel_lead: double (nullable = true)\n",
      " |-- lead_generation_lead: double (nullable = true)\n",
      " |-- purchase_onsite_conversion__purchase: double (nullable = true)\n",
      " |-- purchase_offsite_conversion__fb_pixel_purchase: double (nullable = true)\n",
      " |-- purchase_app_custom_event__fb_mobile_purchase: double (nullable = true)\n",
      " |-- purchase_omni_purchase: double (nullable = true)\n",
      " |-- registration_omni_complete_registration: double (nullable = true)\n",
      " |-- registration_offsite_conversion__fb_pixel_complete_registration: double (nullable = true)\n",
      " |-- search_offsite_conversion__fb_pixel_search: double (nullable = true)\n",
      " |-- date: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obj_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225c841a-0340-4593-8e78-b0afa634709b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.37495635e-07, 6.05960405e-04, 1.57423830e-02],\n",
       "       [4.31600239e-06, 2.55332090e-01, 1.89349113e-02],\n",
       "       [2.17828436e-06, 7.86019924e-05, 1.10635031e-01],\n",
       "       [5.64449338e-07, 5.37139148e-05, 4.88539078e-05],\n",
       "       [5.83393251e-07, 3.35899590e-05, 6.29119751e-04],\n",
       "       [6.18729918e-07, 2.31401675e-04, 8.32152986e-03],\n",
       "       [1.00000000e+00, 1.13202009e-04, 5.19076931e-02],\n",
       "       [6.80268877e-07, 6.09142365e-05, 8.17157021e-03],\n",
       "       [1.06622809e-06, 4.21536440e-03, 2.53092714e-02],\n",
       "       [5.31499361e-06, 1.33116559e-04, 1.82910435e-01],\n",
       "       [9.21398593e-07, 3.50233770e-05, 8.59839179e-03],\n",
       "       [3.40832010e-07, 4.07962080e-01, 1.74572106e-03],\n",
       "       [8.76555827e-06, 1.00000000e+00, 4.72266028e-01],\n",
       "       [2.06757236e-06, 1.61512889e-03, 1.74369791e-02],\n",
       "       [1.22107365e-05, 1.42476138e-03, 1.00000000e+00],\n",
       "       [5.47567397e-08, 2.87349081e-05, 2.66488359e-02],\n",
       "       [2.73860367e-06, 2.27150568e-04, 1.59766841e-02],\n",
       "       [9.15063955e-08, 9.20999634e-06, 4.07404838e-04],\n",
       "       [5.82286929e-09, 0.00000000e+00, 7.81870561e-06],\n",
       "       [2.09939900e-07, 1.19317401e-05, 2.95725637e-03],\n",
       "       [7.99016326e-08, 2.78888686e-06, 9.94421466e-03],\n",
       "       [0.00000000e+00, 2.58159939e-06, 6.29709188e-04],\n",
       "       [4.78805771e-08, 2.42410818e-06, 2.84505534e-03],\n",
       "       [4.36315298e-08, 3.54825616e-06, 5.37424191e-03],\n",
       "       [1.17205496e-07, 2.23144392e-06, 1.43085780e-03],\n",
       "       [4.67019991e-08, 1.98561255e-06, 6.65838196e-04],\n",
       "       [2.52807263e-08, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.59685467e-09, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler= MinMaxScaler()\n",
    "scaled_arr = scaler.fit_transform(_plot_df[_act_met_cols_lst])\n",
    "scaled_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ad6d13-32ee-4e2b-88d6-6b6c33b1bff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.67780930e+05, 2.74321082e+06, 9.08055000e+03],\n",
       "       [2.13000527e+06, 1.15590020e+09, 1.09220700e+04],\n",
       "       [1.07824862e+06, 3.55834860e+05, 6.38167000e+04],\n",
       "       [2.84242260e+05, 2.43165380e+05, 2.81800000e+01],\n",
       "       [2.93562660e+05, 1.52063300e+05, 3.62890000e+02],\n",
       "       [3.10948290e+05, 1.04756610e+06, 4.80004000e+03],\n",
       "       [4.91999716e+11, 5.12470740e+05, 2.99414900e+04],\n",
       "       [3.41225440e+05, 2.75761570e+05, 4.71354000e+03],\n",
       "       [5.31117260e+05, 1.90831499e+07, 1.45989400e+04],\n",
       "       [2.62150866e+06, 6.02624830e+05, 1.05506730e+05],\n",
       "       [4.59861190e+05, 1.58552450e+05, 4.95974000e+03],\n",
       "       [1.74222600e+05, 1.84686323e+09, 1.00697000e+03],\n",
       "       [4.31918547e+06, 4.52704632e+09, 2.72413350e+05],\n",
       "       [1.02377835e+06, 7.31176331e+06, 1.00580300e+04],\n",
       "       [6.01421218e+06, 6.44996074e+06, 5.76821820e+05],\n",
       "       [3.34736500e+04, 1.30084260e+05, 1.53716300e+04],\n",
       "       [1.35392556e+06, 1.02832114e+06, 9.21570000e+03],\n",
       "       [5.15544700e+04, 4.16940800e+04, 2.35000000e+02],\n",
       "       [9.39820000e+03, 0.00000000e+00, 4.51000000e+00],\n",
       "       [1.09823720e+05, 5.40155400e+04, 1.70581000e+03],\n",
       "       [4.58449300e+04, 1.26254200e+04, 5.73604000e+03],\n",
       "       [6.53335000e+03, 1.16870200e+04, 3.63230000e+02],\n",
       "       [3.00905800e+04, 1.09740500e+04, 1.64109000e+03],\n",
       "       [2.80000500e+04, 1.60631200e+04, 3.09998000e+03],\n",
       "       [6.41984200e+04, 1.01018500e+04, 8.25350000e+02],\n",
       "       [2.95107200e+04, 8.98896000e+03, 3.84070000e+02],\n",
       "       [1.89714600e+04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.07630000e+04, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_arr=np.array(_plot_df[_act_met_cols_lst])\n",
    "scaled_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810b834-0ab9-466d-af2c-68e0a6161200",
   "metadata": {},
   "source": [
    "## Fit with Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c83ec3-10d2-4c99-8fb4-335e0449b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# Example historic data (replace with your actual data)\n",
    "# Each row represents a historic data point: [Spend, CPC, CPM, CTR, ROAS]\n",
    "# historic_data = np.array([\n",
    "#     [100, 0.5, 10, 0.02, 4.0],\n",
    "#     [200, 0.6, 12, 0.03, 3.5],\n",
    "#     [300, 0.7, 15, 0.04, 3.0],\n",
    "#     # Add more data points here\n",
    "# ])\n",
    "historic_data = np.array(_data_df)\n",
    "\n",
    "# Split the data into input (Spend) and outputs (CPC, CPM, CTR, ROAS)\n",
    "spend = historic_data[:, 0].astype(np.float32)  # Ensure float32 for TensorFlow\n",
    "cpc = historic_data[:, 1].astype(np.float32)\n",
    "cpm = historic_data[:, 2].astype(np.float32)\n",
    "ctr = historic_data[:, 3].astype(np.float32)\n",
    "roas = historic_data[:, 4].astype(np.float32)\n",
    "\n",
    "# Scale the Spend data to improve numerical stability\n",
    "spend_mean = np.mean(spend)\n",
    "spend_std = np.std(spend)\n",
    "spend_scaled = (spend - spend_mean) / spend_std\n",
    "\n",
    "# Define the probabilistic model\n",
    "def model():\n",
    "    # Priors for the parameters\n",
    "    alpha_cpc = yield tfd.Normal(loc=0.0, scale=1.0, name=\"alpha_cpc\")\n",
    "    beta_cpc = yield tfd.Normal(loc=0.0, scale=1.0, name=\"beta_cpc\")\n",
    "\n",
    "    alpha_cpm = yield tfd.Normal(loc=0.0, scale=1.0, name=\"alpha_cpm\")\n",
    "    beta_cpm = yield tfd.Normal(loc=0.0, scale=1.0, name=\"beta_cpm\")\n",
    "    \n",
    "    alpha_ctr = yield tfd.Normal(loc=0.0, scale=1.0, name=\"alpha_ctr\")\n",
    "    beta_ctr = yield tfd.Normal(loc=0.0, scale=1.0, name=\"beta_ctr\")\n",
    "    \n",
    "    alpha_roas = yield tfd.Normal(loc=0.0, scale=1.0, name=\"alpha_roas\")\n",
    "    beta_roas = yield tfd.Normal(loc=0.0, scale=1.0, name=\"beta_roas\")\n",
    "    \n",
    "    # Likelihoods\n",
    "    cpc_pred = yield tfd.Normal(loc=alpha_cpc + beta_cpc * spend_scaled, scale=0.1, name=\"cpc_pred\")\n",
    "    cpm_pred = yield tfd.Normal(loc=alpha_cpm + beta_cpm * spend_scaled, scale=0.1, name=\"cpm_pred\")\n",
    "    ctr_pred = yield tfd.Normal(loc=alpha_ctr + beta_ctr * spend_scaled, scale=0.01, name=\"ctr_pred\")\n",
    "    roas_pred = yield tfd.Normal(loc=alpha_roas + beta_roas * spend_scaled, scale=0.1, name=\"roas_pred\")\n",
    "\n",
    "# Define the joint distribution\n",
    "joint_distribution = tfd.JointDistributionCoroutineAutoBatched(model)\n",
    "\n",
    "# Define the log probability function\n",
    "def log_prob(alpha_cpc, beta_cpc, alpha_cpm, beta_cpm, alpha_ctr, beta_ctr, alpha_roas, beta_roas):\n",
    "    return joint_distribution.log_prob(\n",
    "        alpha_cpc=alpha_cpc,\n",
    "        beta_cpc=beta_cpc,\n",
    "        alpha_cpm=alpha_cpm,\n",
    "        beta_cpm=beta_cpm,\n",
    "        alpha_ctr=alpha_ctr,\n",
    "        beta_ctr=beta_ctr,\n",
    "        alpha_roas=alpha_roas,\n",
    "        beta_roas=beta_roas,\n",
    "        cpc_pred=cpc,\n",
    "        cpm_pred=cpm,\n",
    "        ctr_pred=ctr,\n",
    "        roas_pred=roas,\n",
    "    )\n",
    "\n",
    "# Use MCMC to sample from the posterior\n",
    "num_results = 10000  # Increase the number of samples\n",
    "num_burnin_steps = 1000  # Increase the burn-in steps\n",
    "\n",
    "# Initialize the chain with reasonable values\n",
    "initial_chain_state = [\n",
    "    tf.constant(0.5),  # alpha_cpc\n",
    "    tf.constant(0.1),  # beta_cpc\n",
    "    tf.constant(10.0),  # alpha_cpm\n",
    "    tf.constant(0.1),  # beta_cpm\n",
    "    tf.constant(0.02),  # alpha_ctr\n",
    "    tf.constant(0.01),  # beta_ctr\n",
    "    tf.constant(4.0),  # alpha_roas\n",
    "    tf.constant(0.1),  # beta_roas\n",
    "]\n",
    "\n",
    "# Define the MCMC kernel\n",
    "hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=log_prob,\n",
    "    num_leapfrog_steps=10,\n",
    "    step_size=0.05,  # Adjusted step size\n",
    ")\n",
    "\n",
    "# Run the MCMC sampler\n",
    "@tf.function\n",
    "def run_chain():\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results=num_results,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        current_state=initial_chain_state,\n",
    "        kernel=hmc_kernel,\n",
    "        trace_fn=None,\n",
    "    )\n",
    "\n",
    "# Run the chain and get samples\n",
    "samples = run_chain()\n",
    "\n",
    "# Extract the posterior samples\n",
    "alpha_cpc_samples, beta_cpc_samples, alpha_cpm_samples, beta_cpm_samples, \\\n",
    "alpha_ctr_samples, beta_ctr_samples, alpha_roas_samples, beta_roas_samples = samples\n",
    "\n",
    "print(\"Completed generating samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7e1f3-0885-406e-a5ff-f800dbe644e2",
   "metadata": {},
   "source": [
    "## Fit with Gamma distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23e0b7c2-327b-4a4d-8c6a-4901e37ae19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# Example historic data (replace with your actual data)\n",
    "# Each row represents a historic data point: [Spend, CPC, CPM, CTR, ROAS]\n",
    "# historic_data = np.array([\n",
    "#     [100, 0.5, 10, 0.02, 4.0],\n",
    "#     [200, 0.6, 12, 0.03, 3.5],\n",
    "#     [300, 0.7, 15, 0.04, 3.0],\n",
    "#     # Add more data points here\n",
    "# ])\n",
    "historic_data = np.array(_data_df)\n",
    "\n",
    "# Split the data into input (Spend) and outputs (CPC, CPM, CTR, ROAS)\n",
    "spend = historic_data[:, 0].astype(np.float32)  # Ensure float32 for TensorFlow\n",
    "cpc = historic_data[:, 1].astype(np.float32)\n",
    "cpm = historic_data[:, 2].astype(np.float32)\n",
    "ctr = historic_data[:, 3].astype(np.float32)\n",
    "roas = historic_data[:, 4].astype(np.float32)\n",
    "\n",
    "# Scale the Spend data to improve numerical stability\n",
    "spend_mean = np.mean(spend)\n",
    "spend_std = np.std(spend)\n",
    "spend_scaled = (spend - spend_mean) / spend_std\n",
    "\n",
    "# Define the probabilistic model\n",
    "def model():\n",
    "    # Priors for the parameters (using Gamma distributions for non-negativity)\n",
    "    alpha_cpc = yield tfd.Gamma(\n",
    "        concentration=1.0, \n",
    "        rate=1.0, \n",
    "        name=\"alpha_cpc\")\n",
    "    beta_cpc = yield tfd.Gamma(concentration=1.0, rate=1.0, name=\"beta_cpc\")\n",
    "    \n",
    "    alpha_cpm = yield tfd.Gamma(concentration=1.0, rate=1.0, name=\"alpha_cpm\")\n",
    "    beta_cpm = yield tfd.Gamma(concentration=1.0, rate=1.0, name=\"beta_cpm\")\n",
    "    \n",
    "    alpha_ctr = yield tfd.Gamma(concentration=1.0, rate=1.0, name=\"alpha_ctr\")\n",
    "    beta_ctr = yield tfd.Gamma(concentration=1.0, rate=1.0, name=\"beta_ctr\")\n",
    "    \n",
    "    alpha_roas = yield tfd.Gamma(concentration=1.0, rate=1.0, name=\"alpha_roas\")\n",
    "    beta_roas = yield tfd.Gamma(concentration=1.0, rate=1.0, name=\"beta_roas\")\n",
    "    \n",
    "    # Likelihoods (using Gamma distributions for non-negativity)\n",
    "    cpc_pred = yield tfd.Gamma(\n",
    "        concentration=alpha_cpc + beta_cpc * spend_scaled,\n",
    "        rate=1.0,\n",
    "        name=\"cpc_pred\"\n",
    "    )\n",
    "    cpm_pred = yield tfd.Gamma(\n",
    "        concentration=alpha_cpm + beta_cpm * spend_scaled,\n",
    "        rate=1.0,\n",
    "        name=\"cpm_pred\"\n",
    "    )\n",
    "    ctr_pred = yield tfd.Gamma(\n",
    "        concentration=alpha_ctr + beta_ctr * spend_scaled,\n",
    "        rate=1.0,\n",
    "        name=\"ctr_pred\"\n",
    "    )\n",
    "    roas_pred = yield tfd.Gamma(\n",
    "        concentration=alpha_roas + beta_roas * spend_scaled,\n",
    "        rate=1.0,\n",
    "        name=\"roas_pred\"\n",
    "    )\n",
    "\n",
    "# Define the joint distribution\n",
    "joint_distribution = tfd.JointDistributionCoroutineAutoBatched(model)\n",
    "\n",
    "# Define the log probability function\n",
    "def log_prob(alpha_cpc, beta_cpc, alpha_cpm, beta_cpm, alpha_ctr, beta_ctr, alpha_roas, beta_roas):\n",
    "    return joint_distribution.log_prob(\n",
    "        alpha_cpc=alpha_cpc,\n",
    "        beta_cpc=beta_cpc,\n",
    "        alpha_cpm=alpha_cpm,\n",
    "        beta_cpm=beta_cpm,\n",
    "        alpha_ctr=alpha_ctr,\n",
    "        beta_ctr=beta_ctr,\n",
    "        alpha_roas=alpha_roas,\n",
    "        beta_roas=beta_roas,\n",
    "        cpc_pred=cpc,\n",
    "        cpm_pred=cpm,\n",
    "        ctr_pred=ctr,\n",
    "        roas_pred=roas,\n",
    "    )\n",
    "\n",
    "# Use MCMC to sample from the posterior\n",
    "num_results = 2000  # Increase the number of samples\n",
    "num_burnin_steps = 1000  # Increase the burn-in steps\n",
    "\n",
    "# Initialize the chain with reasonable values\n",
    "initial_chain_state = [\n",
    "    tf.constant(1.0),  # alpha_cpc\n",
    "    tf.constant(1.0),  # beta_cpc\n",
    "    tf.constant(1.0),  # alpha_cpm\n",
    "    tf.constant(1.0),  # beta_cpm\n",
    "    tf.constant(1.0),  # alpha_ctr\n",
    "    tf.constant(1.0),  # beta_ctr\n",
    "    tf.constant(1.0),  # alpha_roas\n",
    "    tf.constant(1.0),  # beta_roas\n",
    "]\n",
    "\n",
    "# Define the MCMC kernel\n",
    "hmc_kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "    target_log_prob_fn=log_prob,\n",
    "    num_leapfrog_steps=10,\n",
    "    step_size=0.05,  # Adjusted step size\n",
    ")\n",
    "\n",
    "# Run the MCMC sampler\n",
    "@tf.function\n",
    "def run_chain():\n",
    "    return tfp.mcmc.sample_chain(\n",
    "        num_results=num_results,\n",
    "        num_burnin_steps=num_burnin_steps,\n",
    "        current_state=initial_chain_state,\n",
    "        kernel=hmc_kernel,\n",
    "        trace_fn=None,\n",
    "    )\n",
    "\n",
    "# Run the chain and get samples\n",
    "samples = run_chain()\n",
    "\n",
    "# Extract the posterior samples\n",
    "alpha_cpc_samples, beta_cpc_samples, alpha_cpm_samples, beta_cpm_samples, \\\n",
    "alpha_ctr_samples, beta_ctr_samples, alpha_roas_samples, beta_roas_samples = samples\n",
    "\n",
    "print('Completed generating Gama distribution data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a565c0f-50f8-4b66-8193-39249bc15521",
   "metadata": {},
   "source": [
    "## Predict Performance for Spend Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80abb806-c555-4764-8ccf-cf33a14c39cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected CPC for Spend=72.56: 0.7994794249534607\n",
      "Expected CPM for Spend=72.56: 0.7994794249534607\n",
      "Expected CTR for Spend=72.56: 0.7994794249534607\n",
      "Expected ROAS for Spend=72.56: 0.7994794249534607\n"
     ]
    }
   ],
   "source": [
    "# Predict expected values for a given Spend\n",
    "def predict(spend_value):\n",
    "    # Scale the input Spend value\n",
    "    spend_value_scaled = (spend_value - spend_mean) / spend_std\n",
    "    \n",
    "    # Compute predictions\n",
    "    # cpc_pred = np.mean(alpha_cpc_samples + beta_cpc_samples * spend_value_scaled)\n",
    "    # cpm_pred = np.mean(alpha_cpm_samples + beta_cpm_samples * spend_value_scaled)\n",
    "    # ctr_pred = np.mean(alpha_ctr_samples + beta_ctr_samples * spend_value_scaled)\n",
    "    # roas_pred = np.mean(alpha_roas_samples + beta_roas_samples * spend_value_scaled)\n",
    "    cpc_pred = alpha_cpc_samples + beta_cpc_samples * spend_value_scaled\n",
    "    cpm_pred = alpha_cpm_samples + beta_cpm_samples * spend_value_scaled\n",
    "    ctr_pred = alpha_ctr_samples + beta_ctr_samples * spend_value_scaled\n",
    "    roas_pred = alpha_roas_samples + beta_roas_samples * spend_value_scaled\n",
    "    \n",
    "    return cpc_pred, cpm_pred, ctr_pred, roas_pred\n",
    "\n",
    "# Example prediction for a given Spend\n",
    "spend_value = 72.56  # Replace with your desired Spend value\n",
    "cpc_pred, cpm_pred, ctr_pred, roas_pred = predict(spend_value)\n",
    "\n",
    "print(f\"Expected CPC for Spend={spend_value}: {np.mean(cpc_pred)}\")\n",
    "print(f\"Expected CPM for Spend={spend_value}: {np.mean(cpm_pred)}\")\n",
    "print(f\"Expected CTR for Spend={spend_value}: {np.mean(ctr_pred)}\")\n",
    "print(f\"Expected ROAS for Spend={spend_value}: {np.mean(roas_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92be43-b8d2-4081-a4a6-bbd3f791ac54",
   "metadata": {},
   "outputs": [],
   "source": [
    "643.58975     4.068199    83.871559     3.038284     3.730636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a9618c4-275a-45f1-82a7-75697c61e07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spend_usd</th>\n",
       "      <th>CPC</th>\n",
       "      <th>CPM</th>\n",
       "      <th>CTR</th>\n",
       "      <th>ROAS</th>\n",
       "      <th>click</th>\n",
       "      <th>impressions</th>\n",
       "      <th>frequency</th>\n",
       "      <th>reach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.44</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>11.398230</td>\n",
       "      <td>1.238938</td>\n",
       "      <td>18.636646</td>\n",
       "      <td>7</td>\n",
       "      <td>565</td>\n",
       "      <td>1.134538</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.227513</td>\n",
       "      <td>1.322751</td>\n",
       "      <td>18.190000</td>\n",
       "      <td>5</td>\n",
       "      <td>378</td>\n",
       "      <td>1.192429</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.84</td>\n",
       "      <td>1.845714</td>\n",
       "      <td>29.397042</td>\n",
       "      <td>1.592719</td>\n",
       "      <td>9.854876</td>\n",
       "      <td>14</td>\n",
       "      <td>879</td>\n",
       "      <td>1.153543</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.29</td>\n",
       "      <td>1.086000</td>\n",
       "      <td>10.745383</td>\n",
       "      <td>0.989446</td>\n",
       "      <td>5.831799</td>\n",
       "      <td>15</td>\n",
       "      <td>1516</td>\n",
       "      <td>1.179767</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.54</td>\n",
       "      <td>1.245882</td>\n",
       "      <td>55.933099</td>\n",
       "      <td>4.489437</td>\n",
       "      <td>8.462386</td>\n",
       "      <td>51</td>\n",
       "      <td>1136</td>\n",
       "      <td>1.347568</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>72.56</td>\n",
       "      <td>0.980541</td>\n",
       "      <td>48.373333</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>0.663589</td>\n",
       "      <td>74</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.255230</td>\n",
       "      <td>1195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>49.69</td>\n",
       "      <td>1.014082</td>\n",
       "      <td>41.134106</td>\n",
       "      <td>4.056291</td>\n",
       "      <td>5.895150</td>\n",
       "      <td>49</td>\n",
       "      <td>1208</td>\n",
       "      <td>1.391705</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5401</th>\n",
       "      <td>36.70</td>\n",
       "      <td>0.965789</td>\n",
       "      <td>34.819734</td>\n",
       "      <td>3.605313</td>\n",
       "      <td>3.442234</td>\n",
       "      <td>38</td>\n",
       "      <td>1054</td>\n",
       "      <td>1.299630</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>19.59</td>\n",
       "      <td>0.932857</td>\n",
       "      <td>36.892655</td>\n",
       "      <td>3.954802</td>\n",
       "      <td>7.918836</td>\n",
       "      <td>21</td>\n",
       "      <td>531</td>\n",
       "      <td>1.149351</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>32.99</td>\n",
       "      <td>0.785476</td>\n",
       "      <td>23.957879</td>\n",
       "      <td>3.050109</td>\n",
       "      <td>5.168233</td>\n",
       "      <td>42</td>\n",
       "      <td>1377</td>\n",
       "      <td>1.295390</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2395 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      spend_usd       CPC        CPM       CTR       ROAS  click  impressions  \\\n",
       "0          6.44  0.920000  11.398230  1.238938  18.636646      7          565   \n",
       "1          5.00  1.000000  13.227513  1.322751  18.190000      5          378   \n",
       "2         25.84  1.845714  29.397042  1.592719   9.854876     14          879   \n",
       "3         16.29  1.086000  10.745383  0.989446   5.831799     15         1516   \n",
       "4         63.54  1.245882  55.933099  4.489437   8.462386     51         1136   \n",
       "...         ...       ...        ...       ...        ...    ...          ...   \n",
       "5397      72.56  0.980541  48.373333  4.933333   0.663589     74         1500   \n",
       "5398      49.69  1.014082  41.134106  4.056291   5.895150     49         1208   \n",
       "5401      36.70  0.965789  34.819734  3.605313   3.442234     38         1054   \n",
       "5406      19.59  0.932857  36.892655  3.954802   7.918836     21          531   \n",
       "5409      32.99  0.785476  23.957879  3.050109   5.168233     42         1377   \n",
       "\n",
       "      frequency  reach  \n",
       "0      1.134538    498  \n",
       "1      1.192429    317  \n",
       "2      1.153543    762  \n",
       "3      1.179767   1285  \n",
       "4      1.347568    843  \n",
       "...         ...    ...  \n",
       "5397   1.255230   1195  \n",
       "5398   1.391705    868  \n",
       "5401   1.299630    811  \n",
       "5406   1.149351    462  \n",
       "5409   1.295390   1063  \n",
       "\n",
       "[2395 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data_df[_data_df['spend_usd']<91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6b406-8a72-46cd-918b-6ba2dec95ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
