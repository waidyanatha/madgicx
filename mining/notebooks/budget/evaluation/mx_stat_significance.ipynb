{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b41adb1f-5928-4ca9-86bb-82418dec25ca",
   "metadata": {},
   "source": [
    "# MADGICX's standard adset performance evalution\n",
    "\n",
    "__Diagram of the ad set__ [win lose evaluation flow](https://app.diagrams.net/#G1GMSCJ_EQPm-NUYhxQVNe7bFD-vVQk46P#%7B%22pageId%22%3A%22VbIS5GhQtAIJzmuHBgNp%22%7D) \n",
    "\n",
    "### Check statistical significance\n",
    "\n",
    "* Volumne improving over last 7 days for:\n",
    "   * impressions: number ad view adset\n",
    "   * clicks : number of ad clicks\n",
    "   * conversions: number of subsequent click post ad click\n",
    "   * CTR : Click Through Rate = number of clicks / number of impressions\n",
    "* plot time series of daily mean of performance metric indicators\n",
    "* plot time series of daily adsets below and above performance metric average\n",
    "* setup to run plots for any objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2801e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING CONTROL to display or ignore all warnings\n",
    "'''\n",
    "import warnings; warnings.simplefilter('ignore')     #switch betweeb 'default' and 'ignore'\n",
    "import traceback\n",
    "\n",
    "''' Set debug flag to view extended error messages; else set it to False to turn off debugging mode '''\n",
    "debug = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3bda64",
   "metadata": {},
   "source": [
    "## Instantiate Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e9a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All functional __PROPATTR__-libraries in TIMESERIES-package of ML-module imported successfully!\n",
      "All packages in rezaware ml timeseries RollingStats imported successfully!\n",
      "All functional __PROPATTR__-libraries in OPTIMIZATION-package of BUDGET-module imported successfully!\n",
      "All functional RWADSDATA-libraries in OPTIMIZATION-package of BUDGET-module imported successfully!\n",
      "All packages in rezaware ml timeseries RollingStats imported successfully!\n",
      "All functional RWADSDATA-libraries in OPTIMIZATION-package of BUDGET-module imported successfully!\n",
      "All functional APP-libraries in REZAWARE-package of REZAWARE-module imported successfully!\n",
      "__propAttr__ Class initialization complete\n",
      "All functional __PROPATTR__-libraries in LOADER-package of ETL-module imported successfully!\n",
      "All functional SPARKFILE-libraries in LOADER-package of ETL-module imported successfully!\n",
      "__propAttr__ Class initialization complete\n",
      "sparkFile Class initialization complete\n",
      "rwAdsData Class initialization complete\n",
      "All functional EXECSESSION-libraries in SPARK-package of LIB-module imported successfully!\n",
      "execSession Class initialization complete\n",
      "__propAttr__ Class initialization complete\n",
      "\n",
      "read and write dataset for MCMC sampling class initialization and load complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "# import tensorflow_probability as tfp\n",
    "# import tensorflow as tf\n",
    "\n",
    "proj_dir = os.path.abspath(os.pardir)\n",
    "sys.path.insert(1,proj_dir.split('mining/')[0])\n",
    "# from rezaware.modules.etl.loader import sparkRDBM as db\n",
    "from rezaware.modules.ml.timeseries import rollingstats as roll\n",
    "from mining.modules.budget.optimization import rwAdsDataFile as file\n",
    "from rezaware.modules.lib.spark import execSession\n",
    "\n",
    "''' restart initiate classes '''\n",
    "if debug:\n",
    "    import importlib\n",
    "    roll = importlib.reload(roll)\n",
    "    file=importlib.reload(file)\n",
    "    # attr=importlib.reload(attr)\n",
    "\n",
    "__desc__ = \"read and write dataset for MCMC sampling\"\n",
    "\n",
    "clsFile = file.dataWorkLoads(\n",
    "    desc = \"optimizing action_type budgets for an ad\",\n",
    "    f_store_mode='local-fs',\n",
    "    f_store_root=proj_dir.split('mining/')[0],\n",
    "    jar_dir=None,\n",
    ")\n",
    "clsStats = roll.mlWorkLoads(desc=__desc__)\n",
    "clsSpark = execSession.Spawn()\n",
    "print(\"\\n%s class initialization and load complete!\" % __desc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a328cc66-d9b9-4352-ba28-c6d7a0057b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 937:=============================================>           (4 + 1) / 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------+\n",
      "|updated_time|     adset_id|sum_to_cart|\n",
      "+------------+-------------+-----------+\n",
      "|  2025-02-06|6287207374958|       21.0|\n",
      "|  2025-02-02|6290983114158|       null|\n",
      "|  2025-02-06|6290983118558|      143.0|\n",
      "|  2025-01-25|6333951807635|       null|\n",
      "|  2025-01-25|6333951807835|       null|\n",
      "|  2025-01-25|6333951809035|       null|\n",
      "|  2025-01-25|6333951810435|       null|\n",
      "|  2025-01-25|6333960414435|       null|\n",
      "|  2025-01-25|6333971194235|       null|\n",
      "|  2025-01-25|6335138014835|       null|\n",
      "|  2025-01-23|6336296098761|       39.4|\n",
      "|  2025-01-23|6336627585761|     583.18|\n",
      "|  2025-01-25|6340897185635|       null|\n",
      "|  2025-01-25|6340897185835|       null|\n",
      "|  2025-01-25|6340897186035|       null|\n",
      "|  2025-01-25|6340897186235|       null|\n",
      "|  2025-01-25|6340897212635|       null|\n",
      "|  2025-01-25|6340897213035|       null|\n",
      "|  2025-01-25|6340897213235|       null|\n",
      "|  2025-01-25|6340897213635|       null|\n",
      "+------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "_grp_by_date = sdf.groupBy(F.col('adset_id'), F.col('updated_time'))\\\n",
    "                .agg(F.sum(_num_col).alias(f\"sum_{_num_col}\"))\\\n",
    "                .select('updated_time', 'adset_id', f\"sum_{_num_col}\")\\\n",
    "                .orderBy('adset_id','updated_time')\n",
    "_grp_by_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8b4c3f77-d9b1-49e5-a653-11ccb81d79c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execSession Class initialization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 27 days between min date: 2025-01-22 and max date: 2025-02-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique adset ids: 3996\n",
      "Crossjoined rows = 107892\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "from pyspark.sql.types import StringType, DateType\n",
    "from pyspark.sql import Window\n",
    "\n",
    "''' consecutive list of dates '''\n",
    "_max_date = _grp_by_date.select(F.max('updated_time')).first()[0]\n",
    "_min_date = _grp_by_date.select(F.min('updated_time')).first()[0]\n",
    "_dates_lst=[_min_date+timedelta(days=d) \n",
    "            for d in range(0, (_max_date-_min_date).days, 1)]\n",
    "print(\"Created %d days between min date: %s and max date: %s\" \n",
    "      % (len(_dates_lst), str(_min_date),str(_max_date)))\n",
    "_adset_ids_lst= [x['adset_id'] for x in _grp_by_date.select(F.col('adset_id')).distinct().collect()]\n",
    "print(\"Number of unique adset ids:\", len(_adset_ids_lst))\n",
    "\n",
    "''' create cross joined complete date and adset ids sdf '''\n",
    "adset_ids_sdf = clsSpark.session.createDataFrame(\n",
    "    _adset_ids_lst,StringType())\\\n",
    "    .withColumnRenamed('value','adset_id')\n",
    "\n",
    "dates_sdf = clsSpark.session.createDataFrame(\n",
    "    _dates_lst,DateType())\\\n",
    "    .withColumnRenamed('value','updated_time')\n",
    "all_dates_ids_sdf = adset_ids_sdf.crossJoin(dates_sdf)\n",
    "\n",
    "print(\"Crossjoined rows =\",all_dates_ids_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5db720cb-95fb-4621-a8c5-c545e1755161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed sdf rows =  7200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w = Window.partitionBy(\"adset_id\").orderBy(\"updated_time\")\n",
    "\n",
    "_imputed_sdf = all_dates_ids_sdf\\\n",
    "                    .join(_grp_by_date, [\"adset_id\", \"updated_time\"], \"left\")\\\n",
    "                    .select(\"adset_id\",\"updated_time\",\n",
    "                            *[F.last(F.col(c), ignorenulls=True).over(w).alias(c)\n",
    "                              for c in _grp_by_date.columns \n",
    "                                  if c not in (\"adset_id\", \"updated_time\")])\\\n",
    "                    .dropna()\n",
    "\n",
    "print(\"Imputed sdf rows = \",_imputed_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dbb767fc-6c5c-4a7e-a237-232144d17210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- adset_id: string (nullable = true)\n",
      " |-- updated_time: date (nullable = true)\n",
      " |-- sum_to_cart: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_imputed_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1339ac75-6139-402e-820a-15f1365b35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "_num_col = \"sum_to_cart\"\n",
    "kwargs = {\n",
    "    \"RESULTCOL\" : f\"sma_{_num_col}\"\n",
    "}\n",
    "_moving_sdf = clsStats.simple_moving_stats(\n",
    "    num_col =_num_col,  # numeric column name to apply the rolling computation\n",
    "    date_col='updated_time',  # datetime column name to use as the time stamp\n",
    "    part_col='adset_id',  # partition column name to apply rolling stats to windows\n",
    "    win_len =7,   # window length in days, hous, min\n",
    "    win_unit='DAY', # window length unit of measure by days, hours, minutes\n",
    "    stat_op =\"mean\", # stat operation sum, mean or standard deviation\n",
    "    data = _imputed_sdf,   # data set; that can be converted to pyspark DataFrame\n",
    "    **kwargs,    # key/value pairs to set other parameters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2945e11c-6046-4312-9b99-28498625e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "5743"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Simple moving average results = \",_moving_sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b094f6a7-be3b-4411-a960-e5e6ff7398ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_moving_sdf.filter(F.col('adset_id')==120207252077210665)\\\n",
    "    .select('adset_id', 'updated_time', 'to_cart', 'sma_to_cart').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad39fbc1-d5d2-40e9-bfcf-73bc464dbd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'120203730642500265, 120205561409390341, 120207252077210665, 120207252077360665, 120207284214170036, 120209700380740741, 120210838557760640, 120210902135400093, 120211073424860341, 120211474905670233, 120212516385180167, 120214458651670383, 120214603481340347, 120214603779340347, 120214775799110121, 120214790928760525, 120214807877110190, 120214824975810036, 120214825030090036, 120214938246210218, 120215122519670081, 120215217528090719, 120215312683850513, 120215424357560510, 120215457546220647, 120215467439550383, 120215546238570767, 120215583293450668, 120215669666630479, 120215749346680165, 120216134870020064, 120216404344810011, 120216406583180011, 120216442107970676, 120216568560120526, 120216958789620341, 120217390781250360, 120217840667850729, 120218147182050735, 120218147182080735, 120218161599550735, 120218161599660735, 120218161599670735, 120218183358530428, 120218187602110735, 120218187602330735, 120218187602340735, 120218187602360735, 120218187602390735, 120222407741940059, 120222407741950059, 120222428322520059, 120222428429940059, 120222428429990059, 120222428477120059, 120222428477230059, 120222465272110059, 6500060020321, 6502907953921, 6507651968321, 6560605269121, 6591600411784, 6591989385784, 6596579208921, 6597396074921, 6603012048770, 6603964501121, 6606049884090, 6606889487096, 6606889677296, 6614284530921, 6615761083521, 6617578260170, 6618657542090, 6627874381112, 6628577178112, 6628582649512, 6633534679074, 6649775586732, 6653960124966, 6654293483966, 6663511615035, 6668949777212'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join([x['adset_id'] for x in _moving_sdf.select('adset_id').distinct().collect()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8066d7-a018-4f32-aceb-b0f35fb1d3d2",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5affde1-8813-49be-992b-ccea9edc69e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 850:=============================================>           (4 + 1) / 5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded FullDataset.csv 58280 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "_fpath = \"mining/data/budget/\"\n",
    "_fname = \"FullDataset.csv\"\n",
    "\n",
    "__def_date_attr__=\"updated_time\"\n",
    "__def_realm__='OBJECTIVE'\n",
    "__def_obj__ = 'OUTCOME_LEADS'\n",
    "\n",
    "kwargs = {\n",
    "    \"REALMFILTATTR\" : 'objective',\n",
    "    \"REALMFILTLIST\" : [__def_obj__],\n",
    "    \"UNIXTIMESTAMP\" : __def_date_attr__,\n",
    "}\n",
    "sdf = clsFile.read_realm(\n",
    "    realm = __def_realm__,\n",
    "    to_date = None,\n",
    "    from_date=None,\n",
    "    fname = _fname,\n",
    "    fpath = _fpath,\n",
    "    **kwargs,\n",
    ")\n",
    "print(\"Loaded %s %d rows\" % (_fname, sdf.count()))# sdf.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a62aa6-5fa6-44b6-b749-f32696e57e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "__def_obj_col__ = 'objective'\n",
    "__def_opt_goal__= 'checkout'  # action group\n",
    "__def_dt_cols__ = [f\"unix_{__def_date_attr__}\", __def_date_attr__]\n",
    "__def_ids_cols__ = ['adset_id']\n",
    "__def_ad_met_cols__ = ['spend','impressions', 'clicks', 'reach', \n",
    "                       'frequency', 'CTR', 'CPP', 'CPC', 'CPM']\n",
    "__def_roas_cols__ = ['purchase_value', 'purchase_roas']\n",
    "\n",
    "_goal_act_cols = [x for x in sdf.columns\n",
    "                  if x.find(__def_opt_goal__)==0\n",
    "                  and x not in [*__def_ids_cols__, *__def_ad_met_cols__, \n",
    "                                *__def_dt_cols__, *__def_roas_cols__]]\n",
    "\n",
    "''' Remove goal action cols not greater than zero '''\n",
    "count_dict= {}\n",
    "for act  in _goal_act_cols:\n",
    "    count_dict[act]=sdf.select(act).dropna().count()\n",
    "\n",
    "_act_met_cols_lst = [k for k,v in count_dict.items() if v>0]\n",
    "_act_met_cols_lst\n",
    "\n",
    "''' select data for relevant columns '''\n",
    "sdf=sdf.select(*__def_ids_cols__, *__def_dt_cols__, __def_obj_col__,\n",
    "                         *__def_roas_cols__, *__def_ad_met_cols__, *_act_met_cols_lst)\\\n",
    "                .orderBy(*__def_dt_cols__)\n",
    "\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d17ea-264e-46f7-8424-73cd8df81974",
   "metadata": {},
   "source": [
    "### Retrieve and rename conversion columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ae2a5b-52b7-4c00-b6cc-7e615bf1c491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 3 columns\n"
     ]
    }
   ],
   "source": [
    "# Run cell to list objectives and metrics\n",
    "conv_col_lst = [c for c in sdf.columns if c.find(__def_opt_goal__)==0]\n",
    "new_cols_lst = [c.replace('__',' ').replace('_',' ') for c in conv_col_lst]\n",
    "new_cols_lst = [\"_\".join(c.split()[-2:]) for c in new_cols_lst]\n",
    "\n",
    "for _old_col, _new_col in zip(conv_col_lst, new_cols_lst):\n",
    "    sdf=sdf.withColumnRenamed(_old_col, _new_col)\n",
    "\n",
    "print(\"Converted %d columns\" % len(new_cols_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d11ffa-b7c3-4c8f-bf0b-5531d4123327",
   "metadata": {},
   "source": [
    "## Compute the 7-day moving average of adset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f4f68-d996-4230-8121-20ffb536dbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
